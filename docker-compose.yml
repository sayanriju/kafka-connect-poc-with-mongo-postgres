version: '3.7'
services:
# service for mongoDB sink
  mongodb:
      container_name: MongoDBSink
      image: mongo:latest
      networks:
        mynetwork:
          ipv4_address: 172.30.0.102 
      # ports:
      #   - "27018:27017"


# service for postgresSQL sink
  postgres:
    container_name: PostgreSQLSink
    image: postgres:latest
    networks:
      mynetwork:
        ipv4_address: 172.30.0.103
    # ports:
    #   - "5433:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: kafka1    

# service for kafka
  kafka:
    container_name: Kafka
    networks:
      - mynetwork
    image: confluentinc/cp-kafka:latest
    # ports:
    #   - "9092:9092"
    #   - "19092:19092"
    #   - "29092:29092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,LOCALHOST://localhost:19092,LAN://192.168.1.9:29092
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,LOCALHOST://0.0.0.0:19092,LAN://0.0.0.0:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,LOCALHOST:PLAINTEXT,LAN:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: 1      

# service for zookeeper
  zookeeper:
    container_name: Zookeeper
    networks:
    - mynetwork
    image: confluentinc/cp-zookeeper:latest
    # ports:
    #   - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

# service for kafka-connect
  kafka-connect:
    container_name: KafkaConnect
    networks:
      - mynetwork
    build: 
      context: .
      dockerfile: KafkaConnect.Dockerfile
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: kafka-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: kafka-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: kafka-connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
    # ports:
    #   - "8083:8083"
    depends_on:
      - kafka
    volumes:
      - ./KafkaConnect-configs/worker.properties:/etc/kafka-connect/worker.properties
      - ./KafkaConnect-configs/postgres-sink.properties:/etc/kafka-connect/postgres-sink.properties
      - ./KafkaConnect-configs/mongodb-sink.properties:/etc/kafka-connect/mongodb-sink.properties

    command: bash -c "kafka-topics --create --topic kafka-connect-configs --partitions 1 --replication-factor 1 --if-not-exists --bootstrap-server kafka:9092 && kafka-topics --create --topic kafka-connect-offsets --partitions 1 --replication-factor 1 --if-not-exists --bootstrap-server kafka:9092 && kafka-topics --create --topic kafka-connect-status --partitions 1 --replication-factor 1 --if-not-exists --bootstrap-server kafka:9092 && connect-standalone /etc/kafka-connect/worker.properties /etc/kafka-connect/postgres-sink.properties /etc/kafka-connect/mongodb-sink.properties"

    working_dir: /etc/kafka-connect
      


# service for interceptor (always running consumer -> transformer -> producer)
  interceptor: 
    container_name: KafkaInterceptorNodeS
    networks:
      - mynetwork  
    build:
      dockerfile: interceptor.Dockerfile
    environment:
      KAFKA_LISTENER: kafka:9092
    depends_on: 
      - kafka
  # If you want to run multiple instances of a container with Docker Compose, uncomment the lines below and comment out 'container_name: KafkaInterceptorNodeS' above.
    # deploy:
    #   replicas: 3
    
# service for producer testing api
  testingapi:
    container_name: KafkaTestingAPI
    build:
      dockerfile: testingapi.Dockerfile
    environment:
      KAFKA_LISTENER: kafka:9092
    networks:
      mynetwork:
        ipv4_address: 172.30.0.99
    ports:
      - "3000:3000"
    depends_on: 
      - kafka



networks:
  mynetwork:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.30.0.0/16  # Specify a suitable subnet for your static IPs
  